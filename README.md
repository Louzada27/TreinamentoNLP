## üáßüá∑ Modelos de Classifica√ß√£o de Texto em Portugu√™s com BERTimbau

Este reposit√≥rio cont√©m scripts para treinar e avaliar modelos de classifica√ß√£o de texto em portugu√™s com base na arquitetura **BERTimbau**. O foco est√° em tarefas como:

- ‚úÖ **An√°lise de Sentimento**  
- ‚úÖ **Detec√ß√£o de Discurso de √ìdio**  
- ‚úÖ **Identifica√ß√£o de Linguagem Impr√≥pria**

Todos os modelos desenvolvidos aqui foram aplicados na seguinte aplica√ß√£o pr√°tica:  
üîó [YouTubeSafeKids-Python](https://github.com/Louzada27/YouTubeSafeKids-Python)

---

## üìë Sobre o Projeto

Este projeto fornece um framework completo para realizar **fine-tuning** do modelo [`neuralmind/bert-base-portuguese-cased`](https://huggingface.co/neuralmind/bert-base-portuguese-cased) (BERTimbau) em tarefas de **classifica√ß√£o de texto** no idioma portugu√™s.  
Foram utilizados os seguintes datasets:

- **LexiconPT** (para An√°lise de Sentimento)
- **HateBR** (para Detec√ß√£o de Discurso de √ìdio)
- **OLID-BR** (para Identifica√ß√£o de Linguagem Impr√≥pria)

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Python 3.x**
- **PyTorch**: Framework de deep learning
- **Hugging Face Transformers**: Biblioteca para modelos de PLN de √∫ltima gera√ß√£o
- **Hugging Face Datasets**: Biblioteca para carregar e processar datasets
- **Scikit-learn**: Para m√©tricas de avalia√ß√£o e fun√ß√µes utilit√°rias (como pesos de classe)
- **Pandas**: Para manipula√ß√£o de dados
- **NumPy**: Para opera√ß√µes num√©ricas

---

## üìÅ Estrutura do Projeto

.
‚îú‚îÄ‚îÄ Data-set/                     # Diret√≥rio contendo os datasets
‚îÇ   ‚îú‚îÄ‚îÄ HateBR-main/              # Arquivos do dataset HateBR
‚îÇ   ‚îú‚îÄ‚îÄ lexiconPT-master/         # Arquivos do dataset LexiconPT
‚îÇ   ‚îî‚îÄ‚îÄ ...                       # Outros datasets que podem ser adicionados
‚îú‚îÄ‚îÄ train_sentiment.py            # Script para treinar modelo de an√°lise de sentimento (LexiconPT)
‚îú‚îÄ‚îÄ train_hatbr.py                # Script para treinar modelo no dataset HateBR
‚îú‚îÄ‚îÄ train_olid.py                 # Script para treinar modelo no dataset OLID-BR
‚îú‚îÄ‚îÄ train_model.py                # Script gen√©rico para fine-tuning do BERTimbau (potencialmente menos usado agora)
‚îú‚îÄ‚îÄ test_sentimento.py            # Script para testar o modelo de sentimento
‚îú‚îÄ‚îÄ test_hatbr.py                 # Script para testar o modelo HateBR
‚îú‚îÄ‚îÄ test_olidBr.py                # Script para testar o modelo OLID-BR
‚îú‚îÄ‚îÄ README.md                     # Este arquivo
‚îî‚îÄ‚îÄ ...                           # Outros arquivos de configura√ß√£o/utilit√°rios

---

## üöÄ Como Usar

### 1. Configura√ß√£o

a. **Clone o reposit√≥rio:**
    ```bash
    git clone <url-do-repositorio>
    cd <diretorio-do-repositorio>
    ```

b. **Instale as depend√™ncias:** √â recomendado usar um ambiente virtual.
    ```bash
    pip install torch transformers datasets pandas numpy scikit-learn
    ```
    *(Voc√™ pode precisar de vers√µes espec√≠ficas com base na compatibilidade. Verifique os imports nos scripts se ocorrerem erros.)*

c. **Baixe os Datasets:**
- Link para o dataset **HateBR**: https://github.com/franciellevargas/HateBR
- Link para o dataset **LexiconPT**: https://github.com/sillasgonzaga/lexiconPT
- Link para o dataset **OLID-BR**: https://huggingface.co/datasets/dougtrajano/olid-br

---

### 2. Treinando Modelos

#### HateBR

üß† **Fine-Tuning BERTimbau para Detec√ß√£o de Toxicidade com HateBR**

Este reposit√≥rio cont√©m um script em Python para realizar fine-tuning de modelos BERTimbau no dataset **HateBR**, que possui coment√°rios em portugu√™s rotulados com diferentes n√≠veis de toxicidade:

- 0: N√£o t√≥xico
- 1: T√≥xico
- 2: Discurso de √≥dio

‚ú® **Funcionalidades:**

- Pr√©-processamento autom√°tico do dataset HateBR
- Tokeniza√ß√£o com **BertTokenizer**
- Treinamento com **BertForSequenceClassification** da biblioteca ü§ó **Transformers**
- C√°lculo de m√©tricas por classe (F1, precis√£o, recall, acur√°cia)
- Suporte a **early stopping** e **TensorBoard**
- Totalmente compat√≠vel com **CPU**

#### OLYD-BR
# Fine-Tuning com BERTimbau para Detec√ß√£o de Toxicidade (OLID-BR)

Este projeto realiza o **fine-tuning** de modelos BERT em portugu√™s (como o BERTimbau) para **classifica√ß√£o multilabel de toxicidade** utilizando o dataset **OLID-BR**, uma vers√£o brasileira do OLID (Offensive Language Identification Dataset).

---

## üì¶ Funcionalidades

- Treinamento de modelos BERT para detec√ß√£o de m√∫ltiplas categorias de toxicidade
- C√°lculo de m√©tricas detalhadas (`macro`, `micro`, por classe, etc.)
- Aplica√ß√£o de thresholds espec√≠ficos por classe
- Salvamento de logs e m√©tricas de avalia√ß√£o
- Suporte a pesos customizados (`pos_weight`) para lidar com desbalanceamento

---

## üß† Classes de Toxicidade

O modelo √© treinado para identificar as seguintes classes:

- `health`
- `ideology`
- `insult`
- `lgbtqphobia`
- `other_lifestyle`
- `physical_aspects`
- `profanity_obscene`
- `racism`
- `sexism`
- `xenophobia`
## üõ†Ô∏è T√©cnicas de Treinamento Utilizadas

O modelo foi treinado com as seguintes abordagens e pr√°ticas:

- ‚úÖ **Modelo pr√©-treinado BERTimbau**: `neuralmind/bert-base-portuguese-cased`
- ‚úÖ **Classifica√ß√£o multilabel**: usando fun√ß√£o de perda `BCEWithLogitsLoss`
- ‚úÖ **Pesos por classe (`pos_weight`)**: aplicados para lidar com o desbalanceamento entre classes
- ‚úÖ **Tokeniza√ß√£o com `AutoTokenizer`**: preservando a estrutura lingu√≠stica do portugu√™s
- ‚úÖ **Thresholds personalizados**: valores ajustados por classe para melhorar a performance multilabel
- ‚úÖ **Estrat√©gia de divis√£o do dataset**: treino, valida√ß√£o e teste j√° balanceados via `datasets` HuggingFace
- ‚úÖ **Aprimoramento com `EarlyStoppingCallback`**: para evitar overfitting com `patience=3`
- ‚úÖ **Avalia√ß√£o com m√©tricas multilabel**: incluindo micro/macro F1, Jaccard Score, Hamming Loss
- ‚úÖ **Uso do HuggingFace `Trainer`**: para facilitar e padronizar o loop de treinamento e avalia√ß√£o

Essas t√©cnicas foram escolhidas para maximizar a performance em tarefas de **classifica√ß√£o multilabel com dados desbalanceados** ‚Äî um cen√°rio comum em detec√ß√£o de discurso t√≥xico.

Apesar do foco do modelo ser em toxidade, ele se demostru bastante efdicaz em indetifdca√ß√ß√£o de liguamge improria em textos, pricipal,emte se asscoiado como Regex par o auxlio da tarefa.

#### LEXICON-PT

# An√°lise de Sentimento com BERTimbau e LexiconPT üáßüá∑

Este projeto treina um modelo BERT em portugu√™s para **classifica√ß√£o de sentimentos** (positivo, negativo, neutro) com base no dataset **LexiconPT**.

---

## üìå Objetivo

Realizar fine-tuning de um modelo BERTimbau (`neuralmind/bert-base-portuguese-cased`) para identificar **polaridade sem√¢ntica** em palavras/tweets do portugu√™s brasileiro, utilizando um conjunto de dados lexical.

---

## üõ†Ô∏è T√©cnicas de Treinamento Utilizadas

O modelo foi treinado com diversas boas pr√°ticas de NLP e deep learning:

- ‚úÖ **Modelo pr√©-treinado BERTimbau** (`neuralmind/bert-base-portuguese-cased`)
- ‚úÖ **Classifica√ß√£o de sentimento com 3 classes**: Positivo, Negativo, Neutro
- ‚úÖ **Uso de `CrossEntropyLoss` com pesos de classe** (`class_weights`) para lidar com desbalanceamento de classes
- ‚úÖ **Tokeniza√ß√£o com `BertTokenizer`**, preservando a estrutura do idioma
- ‚úÖ **Uso de `Trainer` personalizado (`WeightedTrainer`)** com override de `compute_loss`
- ‚úÖ **Early Stopping** com `EarlyStoppingCallback(patience=3)` para evitar overfitting
- ‚úÖ **Divis√£o estratificada do dataset** (80% treino, 20% teste)
- ‚úÖ **Avalia√ß√£o com m√©tricas robustas**: F1, precis√£o, recall, acur√°cia
- ‚úÖ **Pr√©-processamento autom√°tico com padding, truncamento e `max_length` configur√°vel**
- ‚úÖ **Treinamento com suporte a `fp16` (mixed precision) para maior efici√™ncia**

---

## üìÅ Dataset

O projeto utiliza o dataset [LexiconPT (Oplexicon v3.0)](https://github.com/rafjaa/lexiconPT), um dicion√°rio de polaridade sem√¢ntica de palavras em portugu√™s.

- **Fonte**: CSV localizado em `app/nlp/Data-set/lexiconPT-master/data/csv/oplexicon_v3.0.csv`
- **Colunas utilizadas**: `term`, `polarity`
- **R√≥tulos mapeados**:
  - `1 ‚Üí 0` (Positivo)
  - `-1 ‚Üí 1` (Negativo)
  - `0 ‚Üí 2` (Neutro)



## 3. Avaliando Modelos
### 1. Modelo de An√°lise de Sentimento (BERTimbau + LexiconPT)

O modelo de an√°lise de sentimento foi treinado para classificar textos em tr√™s categorias: **Positivo**, **Negativo** e **Neutro**, utilizando o dataset **LexiconPT**.

### M√©tricas Gerais:
- **Acur√°cia**: 76.84%
- **Precis√£o**: 76.75%
- **Revoca√ß√£o**: 76.84%
- **F1-Score**: 76.63%

### Matriz de Confus√£o:
| Predito:     | Positivo | Negativo | Neutro |
|--------------|----------|----------|--------|
| **Real: Positivo**  | 1052     | 292      | 360    |
| **Real: Negativo**  | 118      | 2586     | 254    |
| **Real: Neutro**    | 272      | 195      | 1309   |

### Desempenho por Classe:
- **Positivo**:
  - **Precis√£o**: 72.95%
  - **Revoca√ß√£o**: 61.74%
  - **F1-Score**: 66.88%
- **Negativo**:
  - **Precis√£o**: 84.15%
  - **Revoca√ß√£o**: 87.42%
  - **F1-Score**: 85.76%
- **Neutro**:
  - **Precis√£o**: 68.07%
  - **Revoca√ß√£o**: 73.70%
  - **F1-Score**: 70.78%

---

## 2. Modelo de Classifica√ß√£o de Toxicidade (BERTimbau + HateBR)

Este modelo foi projetado para classificar conte√∫dos como **T√≥xicos** ou **N√£o T√≥xicos**, utilizando o dataset **HateBR**.

### M√©tricas Gerais:
- **Acur√°cia**: 96.71%
- **Precis√£o**: 96.72%
- **Revoca√ß√£o**: 96.71%
- **F1-Score**: 96.71%

### Matriz de Confus√£o:
| Predito:      | N√£o T√≥xico | T√≥xico |
|---------------|------------|--------|
| **Real: N√£o T√≥xico** | 3369       | 131    |
| **Real: T√≥xico**    | 99        | 3401   |

### Desempenho por Classe:
- **N√£o T√≥xico**:
  - **Precis√£o**: 97.15%
  - **Revoca√ß√£o**: 96.26%
  - **F1-Score**: 96.70%
- **T√≥xico**:
  - **Precis√£o**: 96.29%
  - **Revoca√ß√£o**: 97.17%
  - **F1-Score**: 96.73%

---

## 3. Detec√ß√£o de linguagem impropria (BERTimbau + OLYD-BR)


## M√©tricas Gerais

- **Loss de Avalia√ß√£o**: 0.1867
- **Acur√°cia**: 51.44%
- **F1-Score (M√©dia Ponderada)**: 74.30%
- **Micro F1-Score**: 77.83%
- **Macro F1-Score**: 35.69%
- **Precis√£o (M√©dia Ponderada)**: 76.98%
- **Revoca√ß√£o (M√©dia Ponderada)**: 74.63%
- **Hamming Loss**: 0.0661
- **Jaccard Score (M√©dia Ponderada)**: 63.01%

---

## M√©tricas por Classe

A seguir, as m√©tricas detalhadas de F1-Score, Precis√£o e Revoca√ß√£o para cada classe.

| Classe                      | F1-Score  | Precis√£o  | Revoca√ß√£o |
|-----------------------------|-----------|-----------|-----------|
| **Sa√∫de**                    | 0.0       | 0.0       | 0.0       |
| **Ideologia**                | 0.6343    | 0.6728    | 0.6000    |
| **Insulto**                  | 0.8996    | 0.8578    | 0.9456    |
| **LGBTQIA+ Fobia**           | 0.4429    | 0.6739    | 0.3298    |
| **Outros Estilos de Vida**   | 0.2000    | 0.6667    | 0.1176    |
| **Aspectos F√≠sicos**         | 0.3301    | 0.8500    | 0.2048    |
| **Profanidade/Obscenidade**  | 0.7730    | 0.7927    | 0.7543    |
| **Racismo**                  | 0.0       | 0.0       | 0.0       |
| **Intoler√¢ncia Religiosa**   | 0.2893    | 0.5227    | 0.2000    |
| **Sexismo**                  | 0.0       | 0.0       | 0.0       |

---

- **Classe "Sa√∫de"** e **"Racismo"** n√£o apresentaram nenhum desempenho, com F1-Score, Precis√£o e Revoca√ß√£o iguais a 0. Isso pode indicar que o modelo n√£o foi capaz de identificar exemplos dessas classes no conjunto de teste.
  
- **Classe "Insulto"** apresentou resultados muito bons, com F1-Score de 0.8996, indicando um bom equil√≠brio entre Precis√£o (85.78%) e Revoca√ß√£o (94.56%).

- **Classe "LGBTQIA+ Fobia"** teve um desempenho menor, com F1-Score de 0.4429, refletindo uma menor capacidade de identificar corretamente os exemplos dessa categoria.

- **Classe "Outros Estilos de Vida"** tamb√©m teve uma pontua√ß√£o baixa de F1-Score (0.2000), com uma alta Precis√£o (66.67%) mas baixa Revoca√ß√£o (11.76%).

- **Classe "Aspectos F√≠sicos"** obteve uma Precis√£o muito boa (85.00%), mas o F1-Score e a Revoca√ß√£o indicam que o modelo teve dificuldades em identificar corretamente os exemplos dessa classe.

- **Classe "Profanidade/Obscenidade"** obteve bons resultados com F1-Score de 0.7730, refletindo boa Precis√£o (79.27%) e Revoca√ß√£o (75.43%).

- **Classe "Intoler√¢ncia Religiosa"** teve um desempenho baixo com F1-Score de 0.2893, devido √† baixa Revoca√ß√£o (20.00%).

- **Classe "Sexismo"** tamb√©m n√£o apresentou desempenho, com F1-Score, Precis√£o e Revoca√ß√£o iguais a 0.

---

Esses resultados indicam √°reas de sucesso e de melhoria para o modelo, sendo necess√°rio um ajuste adicional para classes com desempenho insatisfat√≥rio, como "Sa√∫de", "Racismo" e "Sexismo". A classe "Insulto" foi a mais bem identificada, e outras classes como "Profanidade/Obscenidade" e "Ideologia" apresentam bons resultados, mas ainda podem ser melhoradas.

Devido √† maior import√¢ncia da classe "Profanidade/Obscenidade", essencial para identificar linguagem impr√≥pria, foram aplicadas medidas espec√≠ficas para melhorar sua avalia√ß√£o durante o treinamento. Essas medidas inclu√≠ram o uso de um threshold (limiar) de 70% e a aplica√ß√£o da t√©cnica de Class Weights, com um fator de 3. Isso significou atribuir maior peso a essa classe em rela√ß√£o √†s outras, para que o modelo focasse mais em identificar corretamente os exemplos de profanidade/obscenidade.

Com essa abordagem, foi poss√≠vel aumentar a acur√°cia do modelo em 6%, alcan√ßando o melhor desempenho na categoria de profanidade.

O recall, especificamente, foi beneficiado por essa estrat√©gia. O recall √© uma m√©trica que mede a capacidade do modelo de identificar corretamente todos os exemplos positivos de uma classe (neste caso, a classe "Profanidade/Obscenidade"). Uma maior √™nfase nessa classe, por meio dos ajustes de threshold e Class Weights, permitiu uma maior recupera√ß√£o de exemplos reais de profanidade, garantindo que o modelo identificasse de forma mais eficaz as inst√¢ncias relevantes dessa categoria. Isso foi crucial para melhorar o desempenho do modelo, especialmente em tarefas de modera√ß√£o autom√°tica, onde a precis√£o na detec√ß√£o de linguagem inadequada √© fundamental.


####
Apos a conclus√£o suba o modelo para o huggie face e use ele nos testes
## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes. (Assumindo licen√ßa MIT com base no README anterior)