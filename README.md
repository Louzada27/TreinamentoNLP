# ğŸ‡§ğŸ‡· Modelos de ClassificaÃ§Ã£o de Texto em PortuguÃªs com BERTimbau

Este repositÃ³rio contÃ©m scripts para treinar e avaliar modelos de classificaÃ§Ã£o de texto em portuguÃªs com base na arquitetura **BERTimbau**. O foco estÃ¡ em tarefas como:

- âœ… **AnÃ¡lise de Sentimento**  
- âœ… **DetecÃ§Ã£o de Discurso de Ã“dio**  
- âœ… **IdentificaÃ§Ã£o de Linguagem ImprÃ³pria**

Todos os modelos desenvolvidos aqui foram aplicados na seguinte aplicaÃ§Ã£o prÃ¡tica:  
ğŸ”— [YouTubeSafeKids-Python](https://github.com/Louzada27/YouTubeSafeKids-Python)

---

## ğŸ“‘ Sobre o Projeto

Este projeto fornece um framework completo para realizar **fine-tuning** do modelo [`neuralmind/bert-base-portuguese-cased`](https://huggingface.co/neuralmind/bert-base-portuguese-cased) (BERTimbau) em tarefas de **classificaÃ§Ã£o de texto** no idioma portuguÃªs.  
Foram utilizados os seguintes datasets:

- **LexiconPT** (para AnÃ¡lise de Sentimento)
- **HateBR** (para DetecÃ§Ã£o de Discurso de Ã“dio)
- **OLID-BR** (para IdentificaÃ§Ã£o de Linguagem ImprÃ³pria)

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **PyTorch**: Framework de deep learning
- **Hugging Face Transformers**: Biblioteca para modelos de PLN de Ãºltima geraÃ§Ã£o
- **Hugging Face Datasets**: Biblioteca para carregar e processar datasets
- **Scikit-learn**: Para mÃ©tricas de avaliaÃ§Ã£o e funÃ§Ãµes utilitÃ¡rias (como pesos de classe)
- **Pandas**: Para manipulaÃ§Ã£o de dados
- **NumPy**: Para operaÃ§Ãµes numÃ©ricas

---

## ğŸ“ Estrutura do Projeto

. â”œâ”€â”€ Data-set/ # DiretÃ³rio contendo os datasets â”‚ â”œâ”€â”€ HateBR-main/ # Arquivos do dataset HateBR â”‚ â”œâ”€â”€ lexiconPT-master/ # Arquivos do dataset LexiconPT â”‚ â””â”€â”€ ...
â”œâ”€â”€ train_sentiment.py # Script para treinar modelo de anÃ¡lise de sentimento (LexiconPT) â”œâ”€â”€ train_hatbr.py # Script para treinar modelo no dataset HateBR â”œâ”€â”€ train_olid.py # Script para treinar modelo no dataset OLID-BR â”œâ”€â”€ train_model.py # Script genÃ©rico para fine-tuning do BERTimbau (potencialmente menos usado agora) â”œâ”€â”€ test_sentimento.py # Script para testar o modelo de sentimento â”œâ”€â”€ test_hatbr.py # Script para testar o modelo HateBR â”œâ”€â”€ test_OlydBr.py # Script para testar o modelo OLID-BR â”œâ”€â”€ README.md # Este arquivo â””â”€â”€ ... # Outros arquivos de configuraÃ§Ã£o/utilitÃ¡rios
*(Nota: A estrutura do dataset pode variar)*

---

## ğŸš€ Como Usar

### 1. ConfiguraÃ§Ã£o

a. **Clone o repositÃ³rio:**
    ```bash
    git clone <url-do-repositorio>
    cd <diretorio-do-repositorio>
    ```

b. **Instale as dependÃªncias:** Ã‰ recomendado usar um ambiente virtual.
    ```bash
    pip install torch transformers datasets pandas numpy scikit-learn
    ```
    *(VocÃª pode precisar de versÃµes especÃ­ficas com base na compatibilidade. Verifique os imports nos scripts se ocorrerem erros.)*

c. **Baixe os Datasets:**
- Link para o dataset **HateBR**: https://github.com/franciellevargas/HateBR
- Link para o dataset **LexiconPT**: https://github.com/sillasgonzaga/lexiconPT
- Link para o dataset **OLID-BR**: https://huggingface.co/datasets/dougtrajano/olid-br

---

### 2. Treinando Modelos

#### HateBR

ğŸ§  **Fine-Tuning BERTimbau para DetecÃ§Ã£o de Toxicidade com HateBR**

Este repositÃ³rio contÃ©m um script em Python para realizar fine-tuning de modelos BERTimbau no dataset **HateBR**, que possui comentÃ¡rios em portuguÃªs rotulados com diferentes nÃ­veis de toxicidade:

- 0: NÃ£o tÃ³xico
- 1: TÃ³xico
- 2: Discurso de Ã³dio

âœ¨ **Funcionalidades:**

- PrÃ©-processamento automÃ¡tico do dataset HateBR
- TokenizaÃ§Ã£o com **BertTokenizer**
- Treinamento com **BertForSequenceClassification** da biblioteca ğŸ¤— **Transformers**
- CÃ¡lculo de mÃ©tricas por classe (F1, precisÃ£o, recall, acurÃ¡cia)
- Suporte a **early stopping** e **TensorBoard**
- Totalmente compatÃ­vel com **CPU**


---

## ğŸš€ Como Usar

### 1. ConfiguraÃ§Ã£o

a. **Clone o repositÃ³rio:**
    ```bash
    git clone <url-do-repositorio>
    cd <diretorio-do-repositorio>
    ```

b. **Instale as dependÃªncias:** Ã‰ recomendado usar um ambiente virtual.
    ```bash
    pip install torch transformers datasets pandas numpy scikit-learn
    ```
    *(VocÃª pode precisar de versÃµes especÃ­ficas com base na compatibilidade. Verifique os imports nos scripts se ocorrerem erros.)*

c. **Baixe os Datasets:**
- Link para o dataset **HateBR**: https://github.com/franciellevargas/HateBR
- Link para o dataset **LexiconPT**: https://github.com/sillasgonzaga/lexiconPT
- Link para o dataset **OLID-BR**: https://huggingface.co/datasets/dougtrajano/olid-br

---

### 2. Treinando Modelos

#### HateBR

ğŸ§  **Fine-Tuning BERTimbau para DetecÃ§Ã£o de Toxicidade com HateBR**

Este repositÃ³rio contÃ©m um script em Python para realizar fine-tuning de modelos BERTimbau no dataset **HateBR**, que possui comentÃ¡rios em portuguÃªs rotulados com diferentes nÃ­veis de toxicidade:

- 0: NÃ£o tÃ³xico
- 1: TÃ³xico
- 2: Discurso de Ã³dio

âœ¨ **Funcionalidades:**

- PrÃ©-processamento automÃ¡tico do dataset HateBR
- TokenizaÃ§Ã£o com **BertTokenizer**
- Treinamento com **BertForSequenceClassification** da biblioteca ğŸ¤— **Transformers**
- CÃ¡lculo de mÃ©tricas por classe (F1, precisÃ£o, recall, acurÃ¡cia)
- Suporte a **early stopping** e **TensorBoard**
- Totalmente compatÃ­vel com **CPU**

ğŸš€ **Como usar:**

Execute o script com os parÃ¢metros desejados:

```bash
python train_sentiment.py --epochs 4 --batch_size 16 --learning_rate 3e-5
OLID-BR
ğŸ§  Fine-Tuning BERTimbau para DetecÃ§Ã£o de Toxicidade com OLID-BR

Este projeto realiza o fine-tuning de modelos BERT em portuguÃªs (como o BERTimbau) para classificaÃ§Ã£o multilabel de toxicidade utilizando o dataset OLID-BR, uma versÃ£o brasileira do OLID (Offensive Language Identification Dataset).

Funcionalidades:

Treinamento de modelos BERT para detecÃ§Ã£o de mÃºltiplas categorias de toxicidade

CÃ¡lculo de mÃ©tricas detalhadas (macro, micro, por classe, etc.)

AplicaÃ§Ã£o de thresholds especÃ­ficos por classe

Salvamento de logs e mÃ©tricas de avaliaÃ§Ã£o

Suporte a pesos customizados (pos_weight) para lidar com desbalanceamento

3. Avaliando Modelos
Modelo de AnÃ¡lise de Sentimento (BERTimbau + LexiconPT)
Este modelo foi treinado para classificar sentimentos em trÃªs categorias: Positivo, Negativo e Neutro. A seguir, os principais resultados obtidos durante a avaliaÃ§Ã£o no conjunto de teste:

MÃ©tricas Gerais:

AcurÃ¡cia: 76.84%

PrecisÃ£o: 76.75%

RevocaÃ§Ã£o: 76.84%

F1-Score: 76.63%

Matriz de ConfusÃ£o:


Predito: Positivo	Predito: Negativo	Predito: Neutro
Real: Positivo	1052	292
Real: Negativo	118	2586
Real: Neutro	272	195
Desempenho por Classe:

Positivo:

PrecisÃ£o: 72.95%

RevocaÃ§Ã£o: 61.74%

F1-Score: 66.88%

Negativo:

PrecisÃ£o: 84.15%

RevocaÃ§Ã£o: 87.42%

F1-Score: 85.76%

Neutro:

PrecisÃ£o: 68.07%

RevocaÃ§Ã£o: 73.70%

F1-Score: 70.78%

Modelo de ClassificaÃ§Ã£o de Toxicidade (ModeloToxidade2.0)
MÃ©tricas Gerais:

AcurÃ¡cia: 96.71%

PrecisÃ£o: 96.72%

RevocaÃ§Ã£o: 96.71%

F1-Score: 96.71%

Matriz de ConfusÃ£o:


Predito: NÃ£o TÃ³xico	Predito: TÃ³xico
Real: NÃ£o TÃ³xico	3369
Real: TÃ³xico	99
Desempenho por Classe:

NÃ£o TÃ³xico:

PrecisÃ£o: 97.15%

RevocaÃ§Ã£o: 96.26%

F1-Score: 96.70%

TÃ³xico:

PrecisÃ£o: 96.29%

RevocaÃ§Ã£o: 97.17%

F1-Score: 96.73%

DetecÃ§Ã£o de Profanidade/Obscenidade
MÃ©tricas:

PrecisÃ£o: 76.44%

RevocaÃ§Ã£o: 78.03%

F1-Score: 77.23%

ğŸš¨ ImportÃ¢ncia: Esta etapa Ã© crucial para a seguranÃ§a online de pÃºblicos sensÃ­veis (como crianÃ§as), sendo uma ferramenta eficaz para sistemas de moderaÃ§Ã£o automÃ¡tica em ambientes virtuais.

4. Subindo o Modelo para o Hugging Face
ApÃ³s a conclusÃ£o dos treinamentos, o modelo pode ser facilmente carregado e testado no Hugging Face para facilitar o uso em produÃ§Ã£o.

ğŸ“„ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

---

Agora, a seÃ§Ã£o de resultados e explicaÃ§Ãµes do projeto foi devidamente organizada e formatada para um arquivo `README.md` com a estrutura correta.
